# Core ML & Inference
torch>=2.1.0
vllm>=0.2.0
transformers>=4.35.0
accelerate>=0.24.0

# Web Framework & API
fastapi>=0.95.0
uvicorn[standard]>=0.22.0
pydantic>=2.0.0

# Redis Integration
redis>=4.5.4
hiredis>=2.2.3

# Logging & Monitoring
python-json-logger>=2.0.7

# Development & Testing
pytest>=7.3.1
httpx>=0.24.0
locust>=2.15.1

# Optional: Performance Monitoring
prometheus-client>=0.16.0

# AWQ Quantization
autoawq>=0.1.0

# Optional: CUDA Support
nvidia-cuda-runtime-cu11
nvidia-cudnn-cu11

prometheus-fastapi-instrumentator==11.2.0
pytest==8.2.0
locust==2.26.1